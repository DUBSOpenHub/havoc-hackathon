# ğŸŸï¸ Havoc Hackathon

> A **CLI-native adversarial AI orchestration harness** designed to stress-test ideas through parallel multi-agent competition and blind adjudication. âš¡

[![GitHub](https://img.shields.io/badge/GitHub-Copilot_CLI-blue?logo=github)](https://github.com/features/copilot)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Security Policy](https://img.shields.io/badge/Security-Policy-brightgreen?logo=github)](SECURITY.md)

<p align="center">
  <img src="docs/images/hackathon-winner-reveal.png" alt="Havoc Hackathon  -  podium and detailed scoreboard" width="700">
</p>

---

## ğŸ¤” What Is This?

**Havoc Hackathon** is a [Copilot CLI skill](https://docs.github.com/copilot/concepts/agents/about-copilot-cli) that turns your terminal into a competitive arena. Give it any task  -  code, design, review, branding  -  and it dispatches multiple AI models to compete head-to-head, scores them with a sealed panel, and declares a winner with esports-level drama. ğŸ¤ğŸ”¥

### ğŸ’¡ Why This Exists

I wanted a place to stress-test any idea  -  not just code, but copy, designs, architecture decisions, naming, anything. Instead of asking one model and hoping for the best, Havoc Hackathon lets you throw an idea into the arena and see how multiple AIs attack it independently, then find out which approach actually holds up under blind evaluation.

### ğŸ§¬ Design Philosophy

Havoc Hackathon is an **adversarial orchestration harness**  -  not just a wrapper around model APIs. The design is intentional:

- **Why adversarial?**  -  A single model gives you one perspective. Pitting models against each other on the same task with identical prompts exposes blind spots, surfaces diverse approaches, and produces objectively better output through competitive pressure.
- **Why blind adjudication?**  -  Judges never see which model produced which submission. Outputs are anonymized and randomly shuffled before scoring. Three independent judge models score each submission, and the final score is the **median consensus**  -  eliminating individual judge bias. This is the same principle behind double-blind peer review, applied to AI.
- **Why parallel?**  -  All contestants are dispatched simultaneously via background agents. No model sees another's work. No sequential contamination. The competition is fair by construction.
- **Why CLI-native?**  -  This isn't a web app or a notebook. It's built for the terminal, where developers already live. It leverages Copilot CLI's native `task` tool for parallel multi-agent dispatch, `sql` for persistent ELO tracking, and markdown rendering for the ceremony  -  zero external dependencies.

The result: instead of asking *one* AI for an answer and hoping it's good, you force *multiple* AIs to compete, then let a *separate panel* of AIs decide which one actually won  -  all without any model knowing who it's up against.

### Key Features

- ğŸ **Parallel model dispatch**  -  3+ models race on the same task simultaneously
- âš–ï¸ **Sealed panel judging**  -  3 judge models score anonymized submissions
- ğŸ“ˆ **ELO rating system**  -  persistent leaderboard tracks model performance across sessions
- ğŸ§¬ **Intelligent merge**  -  cherry-pick the best components from each submission
- ğŸ† **Full ceremony**  -  ASCII podiums, dramatic reveals, live play-by-play narration
- ğŸ”„ **Adaptive rubrics**  -  scoring criteria adjust based on task type and competition tightness
- ğŸ™ï¸ **Audience participation**  -  vote alongside the judges and compare your taste
- ğŸ”¥ **Rematch mode**  -  tiebreaker round when scores are too close to call
- ğŸ“¼ **Replay export**  -  save the full hackathon as a shareable markdown highlight reel
- ğŸ“Š **Post-match analytics**  -  model performance trends, win rates, and head-to-head records

---

## ğŸ“¦ Installation

### Prerequisites

- [GitHub Copilot CLI](https://github.com/github/copilot-cli) installed
- An active [Copilot subscription](https://github.com/features/copilot/plans)

### Add the Skill

#### Instant Install (no clone needed) âš¡

```bash
mkdir -p ~/.copilot/skills/havoc-hackathon ~/.copilot/agents && \
  curl -sL https://raw.githubusercontent.com/DUBSOpenHub/havoc-hackathon/main/skills/havoc-hackathon/SKILL.md \
    -o ~/.copilot/skills/havoc-hackathon/SKILL.md && \
  curl -sL https://raw.githubusercontent.com/DUBSOpenHub/havoc-hackathon/main/agents/havoc-hackathon.agent.md \
    -o ~/.copilot/agents/havoc-hackathon.agent.md && \
  echo "âœ… Installed! Run /skills reload in Copilot CLI, then say: run hackathon"
```

#### Full Install (clone the repo)

```bash
git clone https://github.com/DUBSOpenHub/havoc-hackathon.git && \
  mkdir -p ~/.copilot/skills ~/.copilot/agents && \
  cp -r havoc-hackathon/skills/havoc-hackathon ~/.copilot/skills/ && \
  cp havoc-hackathon/agents/havoc-hackathon.agent.md ~/.copilot/agents/ && \
  echo "âœ… Havoc Hackathon installed! Run /skills reload in Copilot CLI."
```

<details>
<summary>Other options</summary>

**Auto-discovery (run from repo):**

```bash
git clone https://github.com/DUBSOpenHub/havoc-hackathon.git
cd havoc-hackathon
copilot
```

The skill at `.github/skills/havoc-hackathon/` is automatically discovered  -  no copy needed.

</details>

---

## ğŸ® Usage

### Run a Hackathon

```
> run hackathon  -  build a REST API for a todo app
```

```
> run hackathon  -  review this PR for security issues
```

```
> run hackathon  -  design a landing page hero section
```

### What Happens

1. **ğŸ¬ Opening Ceremony**  -  Arena banner, task summary, contestant lineup, scoring rubric
2. **ğŸ The Race**  -  Models dispatched in parallel with live progress commentary
3. **âš–ï¸ Sealed Panel**  -  3 judges score anonymized submissions on 5 criteria (1-10 each)
4. **ğŸ† Winner Reveal**  -  Drumroll â†’ fireworks â†’ ASCII podium â†’ detailed scoreboard
5. **ğŸ§¬ Smart Merge**  -  Cherry-pick the best pieces from each submission
6. **ğŸ“ˆ ELO Update**  -  Leaderboard changes with commentary
7. **ğŸ«¡ Closing Ceremony**  -  Final stats, optional report export

### Customize

- Choose specific models: `"hackathon with opus, gemini, and codex"`
- Set custom rubric: `"judge on security, performance, and readability"`
- Tournament mode: `"bracket tournament with 6 models"`
- Show stats: `"show leaderboard"` or `"show stats"` anytime

<details>
<summary><strong>ğŸ“¼ Example Run  -  Full Hackathon Transcript</strong></summary>

```
> run hackathon  -  write a Mass Effect themed motivational quote for open source developers

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              âš¡  H A V O C   H A C K A T H O N  âš¡              â•‘
â•‘                                                                  â•‘
â•‘  ğŸŸï¸  THE ARENA IS READY. THE AI MODELS ARE READY TO COMPETE.  ğŸŸï¸  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ TASK: Write a Mass Effect themed motivational quote for open source developers

ğŸ‘‘ CONTESTANTS:
  ğŸ”µ Claude Opus 4.6       (Premium)
  ğŸŸ¢ Codex Max (GPT-5.1)   (Premium)
  ğŸŸ¡ Gemini 3 Pro          (Premium)

âš–ï¸ RUBRIC: Clarity Â· Simplicity Â· Relevance Â· Inspiration Â· Memorability (each /10)

3... 2... 1... GO! ğŸ

ğŸ ALL MODELS CROSSED THE FINISH LINE!
  ğŸ”µ Claude Opus 4.6     âœ… 4s âš¡
  ğŸŸ¢ Codex Max           âœ… 3s âš¡ Speedrun!
  ğŸŸ¡ Gemini 3 Pro        âœ… 10s

âš–ï¸ The panel convenes... ğŸ”’ Submissions anonymized. No favoritism. No mercy.
   ğŸ‘¨â€âš–ï¸ Judges: Claude Opus 4.5 Â· Claude Opus 4.6 Fast Â· Claude Opus 4.6 1M

ğŸ¥ ... ğŸ¥ğŸ¥ ... ğŸ¥ğŸ¥ğŸ¥

ğŸ†ğŸ†ğŸ† AND THE WINNER IS... ğŸ†ğŸ†ğŸ†

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ğŸ†  CHAMPION:  Claude Opus 4.6                                â•‘
â•‘   SCORE: 43/50  Â·  CONSENSUS: STRONG  Â·  ALL JUDGES AGREED     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ… THE PODIUM

                    ğŸ¥‡
                 â”Œâ”€â”€â”€â”€â”€â”€â”
                 â”‚CLAUDEâ”‚
                 â”‚ OPUS â”‚
                 â”‚ 4.6  â”‚
          ğŸ¥ˆ     â”‚  43  â”‚     ğŸ¥‰
       â”Œâ”€â”€â”€â”€â”€â”€â” â”‚      â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”
       â”‚CODEX â”‚ â”‚      â”‚ â”‚GEMINIâ”‚
       â”‚ MAX  â”‚ â”‚      â”‚ â”‚3 PRO â”‚
       â”‚  37  â”‚ â”‚      â”‚ â”‚  35  â”‚
       â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š DETAILED SCOREBOARD
  Category      ğŸ¥‡ Claude Opus  ğŸ¥ˆ Codex Max  ğŸ¥‰ Gemini 3 Pro
  Clarity            9              8              7
  Simplicity         8              7              5
  Relevance          9              8              8
  Inspiration        9              7              8
  Memorability       8              7              7
  TOTAL           43/50          37/50          35/50

ğŸ“ˆ ELO UPDATE
  ğŸ“ˆ Claude Opus 4.6   1532  (+32) â¬†ï¸
  â¡ï¸  Codex Max         1500  (Â±0)
  ğŸ“‰ Gemini 3 Pro      1468  (-32) â¬‡ï¸

GG WP! Scores logged. ELOs updated. ğŸ«¡
```

</details>

---

## ğŸ—ï¸ Architecture

```mermaid
flowchart TD
    USER["ğŸ‘¤ User"] --> SKILL["ğŸŸï¸ SKILL.md<br/>Orchestration rules"]
    SKILL --> DISPATCH["âš¡ Parallel Dispatch<br/>task tool + background mode"]
    DISPATCH --> M1["ğŸ¤– Model A"]
    DISPATCH --> M2["ğŸ¤– Model B"]
    DISPATCH --> M3["ğŸ¤– Model C"]
    M1 --> COLLECT["ğŸ“¦ Collect & Normalize"]
    M2 --> COLLECT
    M3 --> COLLECT
    COLLECT --> ANONYMIZE["ğŸ”’ Anonymize"]
    ANONYMIZE --> J1["âš–ï¸ Judge 1"]
    ANONYMIZE --> J2["âš–ï¸ Judge 2"]
    ANONYMIZE --> J3["âš–ï¸ Judge 3"]
    J1 --> CONSENSUS["ğŸ§‘â€âš–ï¸ Median Consensus"]
    J2 --> CONSENSUS
    J3 --> CONSENSUS
    CONSENSUS --> REVEAL["ğŸ† Winner Reveal"]
    REVEAL --> ELO["ğŸ“ˆ ELO Update"]
    ELO --> MERGE["ğŸ§¬ Smart Merge"]
    SKILL --> SQL["ğŸ—„ï¸ SQL<br/>ELO & history"]
```

---

## ğŸ—ï¸ Project Structure

```
havoc-hackathon/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ CODEOWNERS                    â† ğŸ‘‘ Code ownership rules
â”‚   â”œâ”€â”€ ISSUE_TEMPLATE/               â† ğŸ› Bug & feature templates
â”‚   â”œâ”€â”€ PULL_REQUEST_TEMPLATE.md      â† ğŸ“ PR checklist
â”‚   â”œâ”€â”€ dependabot.yml                â† ğŸ¤– Automated dependency updates
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â””â”€â”€ validate.yml              â† âœ… CI: SKILL.md sync + YAML check
â”‚   â””â”€â”€ skills/
â”‚       â””â”€â”€ havoc-hackathon/
â”‚           â””â”€â”€ SKILL.md              â† ğŸŸï¸ Auto-discovered skill
â”œâ”€â”€ agents/
â”‚   â””â”€â”€ havoc-hackathon.agent.md      â† ğŸ¤– Agent config (for task tool)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ TECHNICAL.md                  â† ğŸ”¬ Technical deep-dive
â”‚   â””â”€â”€ images/                       â† ğŸ“· Screenshots
â”œâ”€â”€ skills/
â”‚   â””â”€â”€ havoc-hackathon/
â”‚       â”œâ”€â”€ SKILL.md                  â† ğŸŸï¸ Canonical skill source
â”‚       â””â”€â”€ catalog.yml               â† ğŸ“‹ Catalog metadata
â”œâ”€â”€ .gitignore
â”œâ”€â”€ CHANGELOG.md                      â† ğŸ“‹ Version history
â”œâ”€â”€ CODE_OF_CONDUCT.md                â† ğŸ¤ Contributor Covenant
â”œâ”€â”€ CONTRIBUTING.md                   â† ğŸ› ï¸ How to contribute
â”œâ”€â”€ LICENSE                           â† ğŸ“„ MIT
â”œâ”€â”€ SECURITY.md                       â† ğŸ”’ Security policy
â”œâ”€â”€ TESTING.md                        â† ğŸ§ª Conversation playbooks & QA
â””â”€â”€ README.md                         â† ğŸ‘‹ You are here!
```

---

## ğŸ“Š Available Models

| Display Name | Model ID | Tier |
|-------------|----------|------|
| Claude Opus 4.6 | `claude-opus-4.6` | Premium |
| Claude Opus 4.6 (Fast) | `claude-opus-4.6-fast` | Premium |
| Claude Opus 4.6 (1M) | `claude-opus-4.6-1m` | Premium |
| Claude Opus 4.5 | `claude-opus-4.5` | Premium |
| Codex Max (GPT-5.1) | `gpt-5.1-codex-max` | Premium |
| Gemini 3 Pro | `gemini-3-pro-preview` | Premium |
| Claude Sonnet 4.6 | `claude-sonnet-4.6` | Standard |
| Claude Sonnet 4.5 | `claude-sonnet-4.5` | Standard |
| Codex (GPT-5.3) | `gpt-5.3-codex` | Standard |
| Codex (GPT-5.2) | `gpt-5.2-codex` | Standard |
| GPT-5.2 | `gpt-5.2` | Standard |
| GPT-5.1 | `gpt-5.1` | Standard |

**Default contestants:** Claude Opus 4.6, Codex Max (GPT-5.1), Gemini 3 Pro â† ALL PREMIUM
**Default judges:** Claude Opus 4.5, Claude Opus 4.6 (Fast), Claude Opus 4.6 (1M) â† ALL PREMIUM

---

## ğŸ”’ Security

See [SECURITY.md](SECURITY.md) for our security policy and how to report vulnerabilities.

---

## ğŸ¤ Contributing

Got ideas to make the arena even better? ğŸ¨ See [CONTRIBUTING.md](CONTRIBUTING.md) for the full guide!

**Quick ways to help:**
- ğŸ› [Report a bug](https://github.com/DUBSOpenHub/havoc-hackathon/issues/new?template=bug_report.md)
- ğŸ’¡ [Suggest a feature](https://github.com/DUBSOpenHub/havoc-hackathon/issues/new?template=feature_request.md)

See [TESTING.md](TESTING.md) for conversation playbooks and QA checklists.

---

## ğŸ“„ License

[MIT](LICENSE)  -  use it, share it, remix it! ğŸ¶

---

## ğŸ™ Built with Love

Created with ğŸ’œ by [DUBSOpenHub](https://github.com/DUBSOpenHub) to help more people discover the joy of GitHub Copilot CLI.

**Let's build!** ğŸš€âœ¨
